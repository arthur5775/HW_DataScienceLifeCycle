{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Laboratory Notes - Week 10: API Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have an idea, or at least have heard of, how computers can communicate with each other.  In the case of application programs, they can access web services through what is termed an Application Programming Interface (API), such as\n",
    "* Rest API\n",
    "* Web API\n",
    "* SOAP API\n",
    "* gRPC\n",
    "\n",
    "For this week's laboratory, we will demonstrate a diabetes prediction service through an API.  We will start with the de-serialisation of some complex data types (a model), write some code to compute the probability of someone having diabetes, and then we will put it into an API service, which we will then access via our browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetic Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this week, we are going to continue on from what we have learned last week about serialisation and de-serialisation.  Let's start by coding this into our Jupyter Notebook.  We only need to import the pickle library.\n",
    "\n",
    "<span style=\"color:red\">import pickle</span>  \n",
    "\n",
    "This diabetic prediction model is based on the Pima tribe of Native Americans who live in the central and southern parts of the state of Arizona, US and also in the northwestern states of Sonora and Chihuahua in Mexico.  The tribe has one of the highest percentage incidences of diabetes, and the dataset for this modelling was from the National Institute of Diabetes and Digestive and Kidney Diseases.  The model built has the objective of predicting whether a patient has diabetes. Do note that all patients here are females of at least 21 years of age and are of Pima Indian heritage.  This dataset is also commonly used in many Data Science teaching materials, and you can access it [here](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database). and it can also be found at the [UCI Machine Learning Repository]([https://archive.ics.uci.edu).\n",
    "\n",
    "A model has been built (I have to admit that is a weak model) with a part of the dataset.  We have serialised and saved that into a file called \"<span style=\"color:red\">final_model.sav</span>\".   Let's load the model that was already built.\n",
    "\n",
    "<span style=\"color:red\">classifier = pickle.load(open('final_model.sav', 'rb'))</span>\n",
    "\n",
    "Now that we have the model \"<span style=\"color:red\">classifier</span>\" (just a name that we gave our model), we can test it by using the <span style=\"color:red\">classifier.predict()</span> function.  What do we need to input the function?  There are 8 features (variables) that were used, and they are:\n",
    "\n",
    "* Pregnancies - Number of times pregnant (ranges from 0 - 17)\n",
    "* Glucose - Plasma glucose concentration over 2 hours in an oral glucose tolerance test (ranges from 0 - 199)\n",
    "* BloodPressure - Diastolic blood pressure (mm Hg)  (ranges from 0 - 122, logically it would not be 0)\n",
    "* SkinThickness - Triceps skin fold thickness (mm) (ranges from 0 to 99, generally not thicker than 50)\n",
    "* Insulin - 2-Hour serum insulin (mu U/ml) (ranges from 0 - 846, normally lower than 300)\n",
    "* BMI - Body mass index (weight in kg/(height in m)^2) (ranges from 0 - 67, usually between 20 and 45)\n",
    "* DiabetesPedigreeFunction - Diabetes pedigree function (ranges from 0 - 2.42, most below 1.25)\n",
    "* Age - Age (years), the model was trained for ages between 21 and 81.\n",
    "\n",
    "The outcome is either a 0 or 1, where 1 indicates the person is clinically diagnosed as having diabetes.  Let's say that we have the following readings for a patient,\n",
    "\n",
    "* Pregnancies - 2\n",
    "* Glucose - 100\n",
    "* BloodPressure - 80\n",
    "* SkinThickness - 20\n",
    "* Insulin - 200\n",
    "* BMI - 35\n",
    "* DiabetesPedigreeFunction - 1.0\n",
    "* Age - 30\n",
    "\n",
    "We then need to put this into an array, in our case a numpy array.\n",
    "\n",
    "<span style=\"color:red\">import numpy as np</span>\n",
    "\n",
    "<span style=\"color:red\">patientData = np.array([2.0, 100.0, 80.0, 20.0, 200.0, 35.0, 1.0, 30.0])  \n",
    "print(patientData)</span>\n",
    "\n",
    "You will notice that the patient data is enclosed in a single set of \"<span style=\"color:red\">[ ]</span>\".  What this means is that it is in a single array as expected.  In order for us to feed it into the model, the model expects to take a list of arrays, meaning that it needs to be in the form of \"[[ ], [ ], ... ,[ ]]\". We then need to have this in the right form and we call this a reshape.  You can try to conduct the prediction with the patientData, but you should encounter an error, e.g.,\n",
    "\n",
    "<span style=\"color:red\">y_pred = classifier.predict(patientData)</span>\n",
    "\n",
    "Understanding that the input is of the wrong format, let's reshape it, and call it <span style=\"color:red\">patientData_reshaped</span>.\n",
    "\n",
    "<span style=\"color:red\">patientData_reshaped = patientData.reshape(1,-1)</span>\n",
    "\n",
    "and proceed to do a prediction.\n",
    "\n",
    "<span style=\"color:red\">y_pred = classifier.predict(patientData_reshaped)</span>\n",
    "\n",
    "You should get either a <span style=\"color:red\">0.</span> or a <span style=\"color:red\">1.</span> (showing positive).  As mentioned above regarding the \"<span style=\"color:red\">[[ ], [ ], ... ,[ ]]</span>\", if we are to provide it a few patients readings, the model can predict for each one with a single input.  We have included a file \"lab11_data.csv\" which consists of unseen data (by the model that has been built) with the respective labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file \"lab11_data.csv\", subset the features and the label, run the prediction using the model loaded above, and display the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are building a tool to accept an external input and respond accordingly, we code a function.  In Python, a function is a section of code that performs a specific and usually repeatedly used task.  It will typically involve giving it some input (not always, e.g., asking a function to return the current time), process the input and return some output.  In Python this is written as follows\n",
    "\n",
    "<span style=\"color:red\">def predict_diabetes():  \n",
    "  \"\"\" The task you want to do\"\"\"</span>\n",
    "\n",
    "It is called in the Python code later using\n",
    "\n",
    "<span style=\"color:red\">predict_diabetes()</span>\n",
    "\n",
    "You can provide the input to the function in between the parenthesis and specify the type as well.  Let's define our function and call it predict_diabetes(), and then we have an input of type \"str\" which produces the output of type \"str\".\n",
    "\n",
    "<span style=\"color:red\">def predict_diabetes(name: str) -> str:</span>\n",
    "\n",
    "We then may want to check the input, to ensure that there is an input provided and it is of the type \"str\".  (Note, we have indented it).\n",
    "\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">if name == False or type(name) != str:</span></p>  \n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Name must contain letters and be of type string\"</span></p>\n",
    "\n",
    "Once it determines that it is being passed a string (note that in this implementation, we assume that the input string is correct, which is never going to be the case), we need to convert the input string into an numpy array.  We use a new library called <span style=\"color:red\">ast</span> to simplify our work here.  Here is the full code:\n",
    "\n",
    "<span style=\"color:red\">import pickle  \n",
    "import numpy as np  \n",
    "import ast</span>\n",
    "\n",
    "<span style=\"color:red\">def predict_diabetes(name):</span>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">if name == False or type(name) != str:</span></p>\n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Name must contain letters and be of type string\"</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">classifier = pickle.load(open('final_model.sav', 'rb'))</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">X = np.array(ast.literal_eval(name)).reshape(1,-1)</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">y_pred = classifier.predict(X)</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">if y_pred == [1.0]:</span></p>\n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Positive, patient is diabetic\"</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">else:</span></p>\n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Negative, patient is not diabetic\"</span></p>\n",
    "\n",
    "Now that we have this function, we can call the function.\n",
    "\n",
    "<span style=\"color:red\">predict_diabetes(\"2.0, 100.0, 80.0, 20.0, 200.0, 35.0, 1.0, 30.0\")</span>\n",
    "\n",
    "Note: In an actual implementation, we will usually send in input in JSON format, parse it and then create the numpy array for the model.  Upon return, we will take the \"<span style=\"color:red\">0.</span>\" or \"<span style=\"color:red\">1.</span>\" and return False or True instead.  However, this is just to illustrate it in the simplest form possible and you can expand your code from here if you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving it as an API using Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can save the code above as a standard Python file (without the \"predict_diabetes(\"\").  You can actually go to your Jupyter Notebook and then go to \"Download as\" and select the \"Python (.py)\".\n",
    "\n",
    "![P1](picture/P1.png)\n",
    "\n",
    "It will save it as the name of your Notebook.  Do change the name appropriately, let's call it \"app.py\".  You would now have a Python application script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Python environment would not have flask installed by default, so you will need to install it.  Other than flask, many commercial applications use Django and some prototyping uses bottle.  However, flask seems to be taking traction lately and we will use it here.  Go to your command line and simply install flask using pip (or other tools, depending on your Python installation or your IDE).  If you have issues installing this (which is common), don't fret, it's not examinable for this course but do try to get it done for your own experience.\n",
    "\n",
    "<span style=\"color:red\">pip install flask</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit your app.py script, you can use your IDE or simply just use Notepad (MS-Windows) Or TextEdit (MacOS).  You will need to add some lines before and after your existing code.\n",
    "\n",
    "<span style=\"color:red\">from flask import Flask, request  \n",
    "import numpy as np  \n",
    "import pickle  \n",
    "import ast</span>\n",
    "\n",
    "<span style=\"color:red\">app = Flask(__name__)</span>\n",
    "\n",
    "<span style=\"color:red\">def predict_diabetes(name):</span>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">if name == False or type(name) != str:</span></p>\n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Name must contain letters and be of type string\"</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">classifier = pickle.load(open('final_model.sav', 'rb'))</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">X = np.array(ast.literal_eval(name)).reshape(1,-1)</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">y_pred = classifier.predict(X)</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">if y_pred == [1.0]:</span></p>\n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Positive, patient is diabetic\"</span></p>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">else:</span></p>\n",
    "<p style=\"margin-left: 80px;\"><span style=\"color:red\">return \"Negative, patient is not diabetic\"</span></p>\n",
    "\n",
    "<span style=\"color:red\">\"\"\" This is a HTTP method, you can read about it on your own\"\"\"</span>\n",
    "\n",
    "<span style=\"color:red\">@app.route('/predict', methods=['GET'])</span>\n",
    "\n",
    "<span style=\"color:red\">def predict():</span>\n",
    "<p style=\"margin-left: 40px;\"><span style=\"color:red\">return predict_diabetes(str(request.query_string, 'utf-8'))</span></p>\n",
    "\n",
    "Once you have done that, save the file and go to your command line and run\n",
    "\n",
    "<span style=\"color:red\">flask run</span>\n",
    "\n",
    "(You can also try to run it using <span style=\"color:red\">python app.py</span>). You should get something like the image below.\n",
    "\n",
    "![P2](picture/P2.png)\n",
    "\n",
    "In short, you now have a web service running on your personal computer (notebook) which you can assess using the HTTP protocol.  Programmers can call this service using different programming languages.  In Python, you will probably need to <span style=\"color:red\">import request</span> and there are some tutorials.  For simplicity, let's use a web browser that can also make the call via the HTTP protocol.  In your browser, key in\n",
    "\n",
    "<span style=\"color:red\">http://localhost:5000/predict?2.0,100.0,80.0,20.0,200.0,35.0,1.0,30.0</span>\n",
    "\n",
    "* localhost means your own PC\n",
    "* 5000 is the port number that was assigned when you ran the app.py script.  You can check the code above.\n",
    "* predict is the path that was specified in your app.py script as well.\n",
    "* ? indicates that the follow on (subsequent) entries are the parameters for the GET.  For simplicity for today, we will just use the raw entry after the ?\n",
    "* 2.0,100.0,80.0,20.0,200.0,35.0,1.0,30.0 is an example parameter of the 8 features used to predict.\n",
    "\n",
    "There are other ways to do this.  Do note that you won't be assessed on this part of the course, this is to assist in your understanding of deploying a model as an API service. \n",
    "\n",
    "This is the last laboratory session for F78DS. We hope that you have gained lots of practice with Python and a good idea of the flow of a typical data science project, and we hope that this has been useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My code part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diabetic Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2. 100.  80.  20. 200.  35.   1.  30.]\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "classifier = pickle.load(open('data/final_model.sav', 'rb'))\n",
    "\n",
    "patientData = np.array([2.0, 100.0, 80.0, 20.0, 200.0, 35.0, 1.0, 30.0])\n",
    "print(patientData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  2. 100.  80.  20. 200.  35.   1.  30.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatientData\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Framework_Arthur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1623\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m \n\u001b[0;32m   1611\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1623\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# decision_function already squeezed it\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m         encoded_classes \u001b[38;5;241m=\u001b[39m (raw_predictions \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Framework_Arthur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1576\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \n\u001b[0;32m   1560\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;124;03m        array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1576\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1579\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\n\u001b[0;32m   1580\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Framework_Arthur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Framework_Arthur\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1093\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1088\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1092\u001b[0m             )\n\u001b[1;32m-> 1093\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1099\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  2. 100.  80.  20. 200.  35.   1.  30.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(patientData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientData_reshaped = patientData.reshape(1,-1)\n",
    "\n",
    "y_pred = classifier.predict(patientData_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n",
      " [[388  88]\n",
      " [136 118]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('data/lab11_data.csv')\n",
    "\n",
    "# Subset the features and the label\n",
    "X = df.iloc[:, 1:-1].values  \n",
    "y_true = df.iloc[:, -1].values  \n",
    "\n",
    "# Pr√©edct the label\n",
    "y_pred = classifier.predict(X)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix :\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive, patient is diabetic'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "def predict_diabetes(name):\n",
    "\n",
    "    if name == False or type(name) != str:\n",
    "        return \"Name must contain letters and be of type string\"\n",
    "    classifier = pickle.load(open('data/final_model.sav', 'rb'))\n",
    "    X = np.array(ast.literal_eval(name)).reshape(1,-1)\n",
    "    y_pred = classifier.predict(X)\n",
    "    if y_pred == [1.0]:\n",
    "        return \"Positive, patient is diabetic\"\n",
    "    else:\n",
    "        return \"Negative, patient is not diabetic\"\n",
    "    \n",
    "predict_diabetes(\"2.0, 100.0, 80.0, 20.0, 200.0, 35.0, 1.0, 30.0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
